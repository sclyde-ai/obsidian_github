---
alias:
    ['同時情報量', 'joint entropy']
---
sum_{x \in \mathcal{X}}\sum_{y \in \mathcal{Y}} p(x, y) \log\ p(x, y) \\ = - \mathbb E[\log\ p(X, Y)] $$